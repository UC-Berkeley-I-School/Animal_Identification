{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "371a2b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import os\n",
    "import numpy as np\n",
    "from utils.utils import create_yolov4_dataset\n",
    "from utils.utils import create_yolov5_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6d8b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 6795/6795 [11.1s elapsed, 0s remaining, 672.4 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# The directory containing the source images\n",
    "data_path = \"/Users/madhuhegde/work/berkeley/W210/leopard.coco/images/train2022/\"\n",
    "\n",
    "# The path to the COCO labels JSON file\n",
    "labels_path = \"/Users/madhuhegde/work/berkeley/W210/leopard.coco/annotations/instances_train2022.json\"\n",
    "\n",
    "# Import the dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    data_path=data_path,\n",
    "    labels_path=labels_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc67b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_yolov5_dataset(dataset, train_test_split = 0.8, output_folder='./'):\n",
    "    anno = [0, 0, 0, 0, 0]\n",
    "    train_files = []\n",
    "    test_files = []\n",
    "       \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    train_image_path =  output_folder+'/train'                   \n",
    "    isExist = os.path.exists(train_image_path)                  \n",
    "                    \n",
    "    if not isExist:\n",
    "        # Create a new directory because it does not exist \n",
    "        os.makedirs(train_image_path+'/images') \n",
    "        os.makedirs(train_image_path+'/labels')  \n",
    "                        \n",
    "    test_image_path =  output_folder+'/test'                       \n",
    "    isExist = os.path.exists(test_image_path)\n",
    "\n",
    "    if not isExist:\n",
    "        os.makedirs(test_image_path+'/images') \n",
    "        os.makedirs(test_image_path+'/labels')                    \n",
    "\n",
    "    for sample in dataset:  \n",
    "        anno[1:] = sample['ground_truth']['detections'][0]['bounding_box']\n",
    "        height = sample['metadata']['height']\n",
    "        width = sample['metadata']['width']\n",
    "        \n",
    "        \n",
    "        if anno[3] >=1.0:\n",
    "            anno[3] = 1-1.0/width\n",
    "            \n",
    "        if anno[4] >=1.0:\n",
    "            anno[4] = 1-1.0/height    \n",
    "\n",
    "        anno[1] = anno[1]+0.5*anno[3]\n",
    "        anno[2] = anno[2]+0.5*anno[4]       \n",
    "     \n",
    "        old_image_file = sample['filepath']\n",
    "       \n",
    "        if(np.random.random_sample() > train_test_split):        \n",
    "            new_image_file = train_image_path + '/images/'+ old_image_file.split(\"/\")[-1]\n",
    "            new_anno_file = train_image_path + '/labels/'+ old_image_file.split(\"/\")[-1]\n",
    "                \n",
    "        else:\n",
    "            new_image_file =  test_image_path + '/images/'+ old_image_file.split(\"/\")[-1]     \n",
    "            new_anno_file = test_image_path + '/labels/'+ old_image_file.split(\"/\")[-1]\n",
    "                        \n",
    "        new_anno_file = new_anno_file.replace(\"jpg\", \"txt\")              \n",
    "           \n",
    "        copy_str = 'cp ' + old_image_file + ' ' + new_image_file\n",
    "        os.system(copy_str)\n",
    "        \n",
    "        with open(new_anno_file, 'w') as fp:\n",
    "            for item in anno:\n",
    "            # write each item on a new line\n",
    "                fp.write(\"%s \" % item)\n",
    "            fp.write(\"\\n\")  \n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337b316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_yolov5_dataset(dataset, output_folder=\"/home/user1/work/darknet/yolov4/darknet\")\n",
    "create_yolov5_dataset(dataset, output_folder=\"/Users/madhuhegde/work/berkeley/W210/Animal_Identification/datasets/leopard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/content/darknet/leopard.coco/images/train2022\"\n",
    "# The path to the COCO labels JSON file\n",
    "labels_path = \"/content/darknet/leopard.coco/annotations/instances_train2022.json\"\n",
    "# Import the COCO dataset\n",
    "dataset1 = fo.Dataset.from_dir(\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    data_path=data_path,\n",
    "    labels_path=labels_path,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f3219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sample in dataset:\n",
    "  path = sample.filepath[:-3] + 'txt'\n",
    "  with open(path, 'w') as f:\n",
    "    anno = sample['ground_truth']['detections'][0]['bounding_box']\n",
    "    height = sample['metadata']['height']\n",
    "    width = sample['metadata']['width']\n",
    "    \n",
    "    if anno[2] >=1.0:\n",
    "        anno[2] = 1-1.0/width\n",
    "        \n",
    "    if anno[3] >=1.0:\n",
    "        anno[3] = 1-1.0/height\n",
    "    anno[0] = anno[0] + 0.5*anno[2]\n",
    "    anno[1] = anno[1] + 0.5*anno[3]\n",
    "    bb = str(anno[0]) + ' ' + str(anno[1]) + ' ' + str(anno[2]) + ' ' + str(anno[3])\n",
    "    f.write('0 ' + bb)\n",
    "    \n",
    "    \n",
    "# Import the YOLO dataset\n",
    "dataset2 = fo.Dataset.from_dir(\n",
    "    dataset_type=fo.types.YOLOv4Dataset,\n",
    "    data_path=data_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab95c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "session2 = fo.launch_app(dataset2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyOne_env",
   "language": "python",
   "name": "fiftyone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
