{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx9e_pXlCuti"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfJfYeZKW_G-"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyfx8ErC7I87",
    "outputId": "8006bf7a-13e4-48f7-a5a0-df35a654321e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!ln -s /content/gdrive/MyDrive /mydrive\n",
    "%cd /mydrive/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMMut8UVCutt"
   },
   "source": [
    "# Experiments\n",
    "We'll go through learning feature embeddings using different loss functions on leopard  dataset. We are using 512-dimensional embeddings.\n",
    "\n",
    "For every experiment Resnet18() is used currently no  hyperparameter search is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcmGBqXeCutw"
   },
   "source": [
    "# Prepare dataset\n",
    "We'll be working on leopard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yWtk_bJJKKBR"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "transform_img = transforms.Compose([\n",
    "    #transforms.Resize(size= (128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225] )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o8lLb7ZNMJ-M",
    "outputId": "f7edde0a-6012-45e9-adcd-bc79ace43e5c"
   },
   "outputs": [],
   "source": [
    "#%cd /mydrive/Animal_Identification/siamese-triplet/\n",
    "\n",
    "from datasets import LeopardDataset\n",
    "\n",
    "MULTI_EMBEDDING = True\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "if MULTI_EMBEDDING:\n",
    "    TRAIN_DATA_PATH = '../../datasets/leopard/classes_64/resize_256/train'\n",
    "    train_dataset = LeopardDataset(image_dir=TRAIN_DATA_PATH,transform=transform_img)\n",
    "    TEST_DATA_PATH = '../../datasets/leopard/classes_64/resize_256/test'\n",
    "    test_dataset = LeopardDataset(image_dir=TEST_DATA_PATH,transform=transform_img)\n",
    "else:\n",
    "    TRAIN_DATA_PATH = '../../datasets/temp'\n",
    "    train_dataset = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=transform_img)\n",
    "    TEST_DATA_PATH = '../../datasets/temp'\n",
    "    test_dataset = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=transform_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcZTFRnjCut3"
   },
   "source": [
    "## Common setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75moY8AyCut_"
   },
   "source": [
    "# Baseline: Classification with softmax\n",
    "We'll train the model for classification and use outputs of penultimate layer as embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7C9H1_nCuvJ"
   },
   "source": [
    "# Online pair/triplet selection - negative mining\n",
    "There are couple of problems with siamese and triplet networks.\n",
    "1. The number of possible pairs/triplets grows **quadratically/cubically** with the number of examples. It's infeasible to process them all\n",
    "2. We generate pairs/triplets randomly. As the training continues, more and more pairs/triplets are easy to deal with (their loss value is very small or even 0), preventing the network from training. We need to provide the network with **hard examples**.\n",
    "3. Each image that is fed to the network is used only for computation of contrastive/triplet loss for only one pair/triplet. The computation is somewhat wasted; once the embedding is computed, it could be reused for many pairs/triplets.\n",
    "\n",
    "To deal with that efficiently, we'll feed a network with standard mini-batches as we did for classification. The loss function will be responsible for selection of hard pairs and triplets within mini-batch. In these case, if we feed the network with 16 images per 10 classes, we can process up to $159*160/2 = 12720$ pairs and $10*16*15/2*(9*16) = 172800$ triplets, compared to 80 pairs and 53 triplets in previous implementation.\n",
    "\n",
    "We can find some strategies on how to select triplets in [2] and [3] *Alexander Hermans, Lucas Beyer, Bastian Leibe, [In Defense of the Triplet Loss for Person Re-Identification](https://arxiv.org/pdf/1703.07737), 2017*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgIGiMwICuvn"
   },
   "source": [
    "## Online triplet selection\n",
    "## Steps\n",
    "1. Create **BalancedBatchSampler** - samples $N$ classes and $M$ samples *datasets.py*\n",
    "2. Create data loaders with the batch sampler\n",
    "3. Define **embedding** *(mapping)* network $f(x)$ - **EmbeddingNet** from *networks.py*\n",
    "4. Define a **TripletSelector** that takes embeddings and original labels and returns valid triplets within a minibatch\n",
    "5. Define **OnlineTripletLoss** that will use a *TripletSelector* and compute *TripletLoss* on such pairs\n",
    "6. Train the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model does not exist\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model\n",
    "    del model\n",
    "except NameError:\n",
    "    print('Model does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_Z2k3EZpT3bB"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from trainer import fit\n",
    "import numpy as np\n",
    "from datasets import BalancedBatchSampler\n",
    "import torch.nn as nn\n",
    "\n",
    "    \n",
    "train_labels = torch.tensor(train_dataset.targets)\n",
    "test_labels = torch.tensor(test_dataset.targets)\n",
    "# We'll create mini batches by sampling labels that will be present in the mini batch and number of examples from each class\n",
    "train_batch_sampler = BalancedBatchSampler(train_labels, n_classes=64, n_samples=8)\n",
    "test_batch_sampler = BalancedBatchSampler(test_labels, n_classes=64, n_samples=2)\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "online_train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_batch_sampler, **kwargs)\n",
    "online_test_loader = torch.utils.data.DataLoader(test_dataset, batch_sampler=test_batch_sampler, **kwargs)\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, drop_last=True)\n",
    "# Set up the network and training parameters\n",
    "from networks import EmbeddingNet\n",
    "from networks import EmbeddingWithSoftmaxNet\n",
    "from networks import MultiPartEmbeddingNet\n",
    "from networks import MultiPartEmbeddingWithSoftmaxNet\n",
    "\n",
    "from losses import OnlineTripletLoss\n",
    "from losses import OnlineSymTripletLoss\n",
    "from losses import OnlineModTripletLoss\n",
    "from utils_triplet import AllTripletSelector\n",
    "from utils_triplet import HardestNegativeTripletSelector\n",
    "from utils_triplet import RandomNegativeTripletSelector\n",
    "from utils_triplet import SemihardNegativeTripletSelector # Strategies for selecting triplets within a minibatch\n",
    "from metrics import AverageNonzeroTripletsMetric\n",
    "from sklearn.metrics import f1_score, classification_report \n",
    "\n",
    "margin = 0.2\n",
    "\n",
    "softmax = True\n",
    "if MULTI_EMBEDDING:\n",
    "    if softmax:\n",
    "        embedding_net = MultiPartEmbeddingWithSoftmaxNet(num_classes=64)\n",
    "    else:\n",
    "        embedding_net = MultiPartEmbeddingNet()\n",
    "else:    \n",
    "    if softmax:\n",
    "        embedding_net = EmbeddingWithSoftmaxNet(num_classes=64)\n",
    "    else:\n",
    "        embedding_net = EmbeddingNet()\n",
    "model = embedding_net\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = OnlineTripletLoss(margin, SemihardNegativeTripletSelector(margin))\n",
    "#loss_fn = OnlineSymTripletLoss(margin, RandomNegativeTripletSelector(margin))\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 20\n",
    "log_interval = 50\n",
    "softmax_loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-bDxqVJCuvs",
    "outputId": "09fb640e-d5d4-4f96-aa33-4ce8b606ebea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/853 (0%)]\tLoss: 0.113212\tAverage nonzero triplets: 1688.0\n",
      "Epoch: 1/20. Train set: Average loss: 0.1132\tAverage nonzero triplets: 1688.0\n",
      "Epoch: 1/20. Validation set: Average loss: 0.1275\tAverage nonzero triplets: 51.0\n",
      "Train: [0/853 (0%)]\tLoss: 0.099085\tAverage nonzero triplets: 1671.0\n",
      "Epoch: 2/20. Train set: Average loss: 0.0991\tAverage nonzero triplets: 1671.0\n",
      "Epoch: 2/20. Validation set: Average loss: 0.1410\tAverage nonzero triplets: 51.0\n"
     ]
    }
   ],
   "source": [
    "fit(online_train_loader, online_test_loader, model, loss_fn, softmax_loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics=[AverageNonzeroTripletsMetric()], multi_class=MULTI_EMBEDDING, softmax=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smvUHdXOyt7r"
   },
   "outputs": [],
   "source": [
    "model_file_name = 'leopard_model_tr.pt'\n",
    "path = f\"/content/gdrive/MyDrive/siamese-triplet/{model_file_name}\" \n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2Uv949SnoGo"
   },
   "outputs": [],
   "source": [
    "def extract_embeddings(dataloader, model, multi_class=False, softmax=False):\n",
    "    embeddings = []\n",
    "    ref_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        if multi_class:\n",
    "            for face, flank, full, target in dataloader:\n",
    "                if cuda:\n",
    "                    #face = face.cuda()\n",
    "                    #flank = flank.cuda()\n",
    "                    full = full.cuda()\n",
    "                if softmax:    \n",
    "                    x,y=model.get_embedding(full)   \n",
    "                    z, preds = torch.max(y.data, 1)\n",
    "                    pred_labels.extend(preds.data.cpu().numpy().tolist())\n",
    "                else:\n",
    "                    x=model.get_embedding(full)\n",
    "                \n",
    "                embeddings.extend(x.data.cpu().numpy())\n",
    "                ref_labels.extend(target.data.cpu().numpy().tolist())\n",
    "        else:      \n",
    "            for data, target in dataloader:\n",
    "                if cuda:\n",
    "                    data = data.cuda()\n",
    "                if softmax:    \n",
    "                    x,y=model.get_embedding(data)   \n",
    "                    z, preds = torch.max(y.data, 1)\n",
    "                    pred_labels.extend(preds.data.cpu().numpy().tolist())\n",
    "                else:\n",
    "                    x=model.get_embedding(data)\n",
    "                \n",
    "                embeddings.extend(x.data.cpu().numpy())\n",
    "                ref_labels.extend(target.data.cpu().numpy().tolist())\n",
    "                \n",
    "    if softmax:        \n",
    "        return embeddings, ref_labels, pred_labels\n",
    "    else:\n",
    "        return embeddings, ref_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HoRFHZs2QHmI",
    "outputId": "6e5a455f-5abc-4eb9-cb52-b0bed3b75dd1"
   },
   "outputs": [],
   "source": [
    "train_eval_loader = data.DataLoader(train_dataset, batch_size=16, shuffle=False,  num_workers=2, drop_last=True, pin_memory=cuda)\n",
    "train_emb, train_ref_labels, train_pred_labels = extract_embeddings(train_eval_loader, model, multi_class=True, softmax=True)\n",
    "print(classification_report(train_pred_labels, train_ref_labels))#, average='weighted'))\n",
    "test_eval_loader = data.DataLoader(test_dataset, batch_size=16, shuffle=False,  num_workers=2, drop_last=True, pin_memory=cuda)\n",
    "test_emb, test_ref_labels, test_pred_labels= extract_embeddings(test_eval_loader, model,multi_class=True, softmax=True)\n",
    "print(classification_report(test_pred_labels, test_ref_labels))#, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(train_emb, train_ref_label)\n",
    "\n",
    "y_pred = clf.predict(train_emb)\n",
    "train_acc = accuracy_score(train_ref_label, y_pred)\n",
    "\n",
    "y_pred = clf.predict(test_emb)\n",
    "test_acc = accuracy_score(test_ref_label, y_pred)\n",
    "\n",
    "print(\"Training Accuracy: \" + str(train_acc))\n",
    "print(\"Testing Accuracy: \" + str(test_acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "name": "Experiments_leopard.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "w251_project",
   "language": "python",
   "name": "w251_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b67f25a65f64e8f86c49664483020ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1fede8ce447d42f5a57f5ad44af281e5",
       "IPY_MODEL_69100e117f8346b9ab6275598b6ddad4",
       "IPY_MODEL_721b12dc1f8140539e91f18c185b014e"
      ],
      "layout": "IPY_MODEL_94a381099b84401c80437b2f2d3c2316"
     }
    },
    "1fede8ce447d42f5a57f5ad44af281e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cefb48e909c243e9b67da383f140a936",
      "placeholder": "​",
      "style": "IPY_MODEL_a8dff44a095c4492bc306a3b2198f154",
      "value": "100%"
     }
    },
    "4023331bb7314fb3a61a83c5730e7ae8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66b1ab01ef474fcdafad404fb9231ae5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69100e117f8346b9ab6275598b6ddad4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66b1ab01ef474fcdafad404fb9231ae5",
      "max": 46830571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9abf83fce1ed4da88f6148b9e16e5ece",
      "value": 46830571
     }
    },
    "721b12dc1f8140539e91f18c185b014e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e1065d3a2c6400095224a7e88e8e4c1",
      "placeholder": "​",
      "style": "IPY_MODEL_4023331bb7314fb3a61a83c5730e7ae8",
      "value": " 44.7M/44.7M [00:03&lt;00:00, 14.4MB/s]"
     }
    },
    "94a381099b84401c80437b2f2d3c2316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9abf83fce1ed4da88f6148b9e16e5ece": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9e1065d3a2c6400095224a7e88e8e4c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8dff44a095c4492bc306a3b2198f154": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cefb48e909c243e9b67da383f140a936": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
