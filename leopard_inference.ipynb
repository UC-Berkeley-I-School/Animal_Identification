{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e110018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from yolov5.detect import run\n",
    "from utils_main.utils import ResizeImages\n",
    "from siamese_triplet.datasets import LeopardDataset\n",
    "from siamese_triplet.networks import EmbeddingNet\n",
    "from siamese_triplet.networks import EmbeddingWithSoftmaxNet\n",
    "from siamese_triplet.networks import MultiPartEmbeddingNet\n",
    "from siamese_triplet.networks import MultiPartEmbeddingWithSoftmaxNet\n",
    "from siamese_triplet.networks import extract_embeddings\n",
    "from siamese_triplet.networks import InferenceNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101cdee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yolov5 folders\n",
    "CROP_FOLDER = '../dataset/'\n",
    "YOLOV5_FOLDER = './yolov5/'\n",
    "YOLOV5_WEIGHTS_FOLDER = YOLOV5_FOLDER + 'yolov5x_weights/best.pt'\n",
    "INPUT_IMAGE_FOLDER = '/home/user1/work/W210/datasets/shared/images/'\n",
    "\n",
    "# Siamese network files/folder\n",
    "model_file_name = 'leop_id_model_july_28.pt'\n",
    "centroid_file_name = 'centroid_july_28.pt'\n",
    "dict_file_name = 'leopard_label_dict.pt'\n",
    "model_path = f\"./siamese_triplet/weights/{model_file_name}\"    \n",
    "centroid_path = f\"./siamese_triplet/weights/{centroid_file_name}\"   \n",
    "labels_dict_path = f\"./siamese_triplet/weights/{dict_file_name}\" \n",
    "\n",
    "# input path to identification\n",
    "RESIZE_IMAGE_PATH = CROP_FOLDER+'resize/'\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcbfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Yolov5 to generate cropped images\n",
    "run(weights=YOLOV5_WEIGHTS_FOLDER,\n",
    "    conf_thres= 0.75,\n",
    "    nosave=True,\n",
    "    data = YOLOV5_FOLDER+'/data/custom.yaml',\n",
    "    project = CROP_FOLDER,\n",
    "    name = '',\n",
    "    source = INPUT_IMAGE_FOLDER,\n",
    "    save_crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cbb442a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate resize images from cropped images\n",
    "resize_images = ResizeImages(in_path=CROP_FOLDER+'crops/',out_path=RESIZE_IMAGE_PATH+'leop_xx')\n",
    "#resize_images.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb686d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Siamese network model and load weights\n",
    "MULTI_EMBEDDING = True\n",
    "softmax = True\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "model = EmbeddingWithSoftmaxNet(num_classes=64)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.centroids = torch.load(centroid_path)\n",
    "labels_dict = torch.load(labels_dict_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c54f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run identification Network\n",
    "\n",
    "infer_network = InferenceNetwork(infer_path=RESIZE_IMAGE_PATH,\n",
    "                                 model = model,\n",
    "                                 labels_dict = labels_dict,\n",
    "                                 infer_labels = True,\n",
    "                                 ood_reject_thresh = 0.675,\n",
    "                                 cuda = cuda\n",
    "                                 )\n",
    "ref_label, pred_label = infer_network.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61ec8036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leop_121 leop_121\n",
      "leop_12 leop_18\n",
      "leop_12 leop_UKN\n",
      "leop_14 leop_UKN\n",
      "leop_UKN leop_UKN\n",
      "leop_15 leop_UKN\n",
      "leop_15 leop_15\n",
      "leop_15 leop_0\n",
      "leop_UKN leop_UKN\n",
      "leop_205 leop_205\n",
      "leop_212 leop_212\n",
      "leop_212 leop_212\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_249\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_249\n",
      "leop_UKN leop_249\n",
      "leop_UKN leop_249\n",
      "leop_UKN leop_249\n",
      "leop_25 leop_UKN\n",
      "leop_25 leop_UKN\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_249\n",
      "leop_UKN leop_249\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_249\n",
      "leop_277 leop_249\n",
      "leop_UKN leop_249\n",
      "leop_280 leop_275\n",
      "leop_280 leop_282\n",
      "leop_280 leop_UKN\n",
      "leop_UKN leop_249\n",
      "leop_282 leop_275\n",
      "leop_UKN leop_249\n",
      "leop_UKN leop_249\n",
      "leop_UKN leop_249\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_249\n",
      "leop_UKN leop_249\n",
      "leop_291 leop_291\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_12\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_UKN\n",
      "leop_7 leop_7\n",
      "leop_80 leop_UKN\n",
      "leop_UKN leop_7\n",
      "leop_UKN leop_UKN\n",
      "leop_UKN leop_7\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred_label)):\n",
    "   print(ref_label[i], pred_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dfe15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w210_env",
   "language": "python",
   "name": "w210_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
