{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e110018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from yolov5.detect import run as yolov5_run\n",
    "from utils_main.utils import ResizeImages\n",
    "from siamese_triplet.datasets import LeopardDataset\n",
    "from siamese_triplet.networks import EmbeddingNet\n",
    "from siamese_triplet.networks import EmbeddingWithSoftmaxNet\n",
    "from siamese_triplet.networks import MultiPartEmbeddingNet\n",
    "from siamese_triplet.networks import MultiPartEmbeddingWithSoftmaxNet\n",
    "from siamese_triplet.networks import extract_embeddings\n",
    "from siamese_triplet.networks import InferenceNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101cdee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yolov5 folders\n",
    "CROP_FOLDER = '../dataset/'\n",
    "YOLOV5_FOLDER = './yolov5/'\n",
    "YOLOV5_WEIGHTS_FOLDER = YOLOV5_FOLDER + 'yolov5x_weights/best.pt'\n",
    "INPUT_IMAGE_FOLDER = '/home/user1/work/W210/datasets/shared/images/'\n",
    "\n",
    "# Siamese network files/folder\n",
    "model_file_name = 'leop_id_model_july_28.pt'\n",
    "centroid_file_name = 'centroid_july_28.pt'\n",
    "dict_file_name = 'leopard_label_dict.pt'\n",
    "model_path = f\"./siamese_triplet/weights/{model_file_name}\"    \n",
    "centroid_path = f\"./siamese_triplet/weights/{centroid_file_name}\"   \n",
    "labels_dict_path = f\"./siamese_triplet/weights/{dict_file_name}\" \n",
    "\n",
    "# input path to identification\n",
    "RESIZE_IMAGE_PATH = CROP_FOLDER+'resize/'\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dcbfd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-7-27 Python-3.9.12 torch-1.11.0 CUDA:0 (NVIDIA TITAN RTX, 24212MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 444 layers, 86193601 parameters, 0 gradients\n",
      "image 1/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_121_002352.jpg: 352x640 1 flank, 1 head, 1 leopard, Done. (0.022s)\n",
      "image 2/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_12_000315.jpg: 480x640 1 head, Done. (0.025s)\n",
      "image 3/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_12_000409.jpg: 480x640 1 head, Done. (0.031s)\n",
      "image 4/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_12_000536.jpg: 480x640 1 head, 1 leopard, Done. (0.025s)\n",
      "image 5/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_12_000552.jpg: 480x640 1 flank, 1 head, 1 leopard, Done. (0.026s)\n",
      "image 6/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_12_000555.jpg: 448x640 Done. (0.024s)\n",
      "image 7/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_153_002482.jpg: 384x640 1 flank, 1 head, 1 leopard, Done. (0.028s)\n",
      "image 8/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_15_000844.jpg: 480x640 1 flank, 1 head, 1 leopard, Done. (0.027s)\n",
      "image 9/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_15_000848.jpg: 480x640 1 head, 1 leopard, Done. (0.025s)\n",
      "image 10/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_15_000869.jpg: 448x640 1 head, Done. (0.023s)\n",
      "image 11/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_15_000972.jpg: 448x640 1 leopard, Done. (0.023s)\n",
      "image 12/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_250_003777.jpg: 384x640 1 flank, 1 head, 1 leopard, Done. (0.026s)\n",
      "image 13/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_252_003445.jpg: 384x640 1 flank, 1 head, 1 leopard, Done. (0.026s)\n",
      "image 14/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_252_006723.jpg: 384x640 1 leopard, Done. (0.025s)\n",
      "image 15/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_253_003455.jpg: 480x640 1 head, 1 leopard, Done. (0.029s)\n",
      "image 16/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_259_003584.jpg: 480x640 1 flank, 1 leopard, Done. (0.026s)\n",
      "image 17/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_25_001522.jpg: 448x640 1 flank, 1 head, 1 leopard, Done. (0.023s)\n",
      "image 18/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_25_001611.jpg: 448x640 1 flank, 1 head, 1 leopard, Done. (0.023s)\n",
      "image 19/19 /media/user1/My4TBHD1/W210/datasets/temp/leop_7_000227.jpg: 448x640 1 flank, 1 leopard, Done. (0.024s)\n",
      "Speed: 1.7ms pre-process, 25.2ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Run Yolov5 to generate cropped images\n",
    "yolov5_run(weights=YOLOV5_WEIGHTS_FOLDER,\n",
    "    conf_thres= 0.75,\n",
    "    nosave=True,\n",
    "    data = YOLOV5_FOLDER+'/data/custom.yaml',\n",
    "    project = CROP_FOLDER,\n",
    "    name = '',\n",
    "    source = INPUT_IMAGE_FOLDER,\n",
    "    save_crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb442a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate resize images from cropped images\n",
    "resize_images = ResizeImages(in_path=CROP_FOLDER+'crops/',out_path=RESIZE_IMAGE_PATH+'leop_xx')\n",
    "resize_images.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb686d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Siamese network model and load weights\n",
    "MULTI_EMBEDDING = True\n",
    "softmax = True\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "model = EmbeddingWithSoftmaxNet(num_classes=64)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.centroids = torch.load(centroid_path)\n",
    "labels_dict = torch.load(labels_dict_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run identification Network\n",
    "\n",
    "infer_network = InferenceNetwork(infer_path=RESIZE_IMAGE_PATH,\n",
    "                                 model = model,\n",
    "                                 labels_dict = labels_dict,\n",
    "                                 infer_labels = True,\n",
    "                                 ood_reject_thresh = 0.675,\n",
    "                                 cuda = cuda\n",
    "                                 )\n",
    "ref_label, pred_label = infer_network.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec8036",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred_label)):\n",
    "   print(ref_label[i], pred_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ba1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w210_env",
   "language": "python",
   "name": "w210_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
